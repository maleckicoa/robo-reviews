{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kr5red/automated-customer-reviews/blob/main/model3_new_ki.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "defe55a7",
      "metadata": {
        "id": "defe55a7"
      },
      "source": [
        "### Import Data & Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83520877",
      "metadata": {
        "id": "83520877",
        "outputId": "161c3d94-7fda-43f3-ad76-643ba3c7db56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([' E-readers', 'Tablets', ' Batteries', ' Kids Electronics',\n",
              "       ' Smart Speakers', ' Streaming Devices'], dtype=object)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from pathlib import Path\n",
        "\n",
        "import data_prep\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "\n",
        "\n",
        "df_resampled = data_prep.make_dataframe()\n",
        "\n",
        "# ADDING SENTIMENT AND CATEGORY COLUMNS\n",
        "with open(\"data/sentiment_columns.pkl\", \"rb\") as f:\n",
        "        sentiment_columns = pickle.load(f)\n",
        "\n",
        "with open(\"data/category_columns.pkl\", \"rb\") as f:\n",
        "        category_columns = pickle.load(f)\n",
        "\n",
        "\n",
        "#with open(\"data/embedding_columns.pkl\", \"rb\") as f:\n",
        "#        embedding_columns = pickle.load(f)\n",
        "\n",
        "\n",
        "df_resampled = df_resampled.merge(sentiment_columns, on=\"new_id\", how=\"left\")\n",
        "\n",
        "df_resampled = df_resampled.merge(category_columns, on=\"new_id\", how=\"left\")\n",
        "\n",
        "#df_resampled = df_resampled.merge(embedding_columns, on=\"new_id\", how=\"left\")\n",
        "\n",
        "df_resampled['predicted_product_category'].unique()\n",
        "#4 ' E-readers', 'Tablets', ' Batteries', ' Smart Home Devices']\n",
        "#6 E-readers', 'Tablets', ' Batteries', ' Kids Electronics',' Smart Speakers', ' Streaming Devices'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fe74261",
      "metadata": {
        "id": "2fe74261"
      },
      "outputs": [],
      "source": [
        "#df_view = df_resampled.drop(columns=[\"sourceURLs\", \"imageURLs\", \"keys\"])\n",
        "#df_view.head(1)\n",
        "\n",
        "#df_view['reviews.didPurchase'].value_counts()\n",
        "#df_view['reviews.doRecommend'].value_counts()\n",
        "\n",
        "#df_view.reviews.numHelpful.sum()\n",
        "#df_view.reviews.rating.sum()\n",
        "\n",
        "#df_view.reviews.rating.value_counts()\n",
        "#df_view['id'].value_counts()\n",
        "#df_view['name'].value_counts()\n",
        "\n",
        "#df_resampled[df_resampled['id']=='AV1YE_muvKc47QAVgpwE'].head(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "301a494b",
      "metadata": {
        "id": "301a494b"
      },
      "source": [
        "#### Pivots of Best and Worst Producst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe2d8e46",
      "metadata": {
        "id": "fe2d8e46"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "out = (\n",
        "    df_resampled\n",
        "    .groupby([\"predicted_product_category\", \"id\"])\n",
        "    .agg(\n",
        "        # existing\n",
        "        count_new_id = (\"new_id\", \"count\"),\n",
        "        count_positive = (\"sentiment\", lambda x: (x == \"positive\").sum()),\n",
        "        count_negative = (\"sentiment\", lambda x: (x == \"negative\").sum()),\n",
        "        count_neutral  = (\"sentiment\", lambda x: (x == \"neutral\").sum()),\n",
        "\n",
        "        # new fields\n",
        "        count_didPurchase  = (\"reviews.didPurchase\", \"sum\"),\n",
        "        count_doRecommend  = (\"reviews.doRecommend\", \"sum\"),\n",
        "        sum_numHelpful     = (\"reviews.numHelpful\", \"sum\"),\n",
        "        sum_rating         = (\"reviews.rating\", \"mean\"),\n",
        "        #first_name = (\"name\", \"first\"),\n",
        "        #longest_name = (\"name\", lambda x: max(x, key=len)),\n",
        "        brand_value = (\"brand\", \"first\"),\n",
        "\n",
        "        # longest name OR fallback to brand\n",
        "        longest_name = (\n",
        "            \"name\",\n",
        "            lambda x: (\n",
        "                max(x.dropna().astype(str), key=len)\n",
        "                if x.dropna().size > 0 and max(x.dropna().astype(str), key=len) != \"\"\n",
        "                else None   # placeholder, will be fixed after .agg()\n",
        "            )\n",
        "        ),\n",
        "\n",
        "\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "out = out[out['count_new_id'] >= 10].reset_index(drop=True)\n",
        "\n",
        "out[\"count_new_id_by_category\"] = (\n",
        "    out.groupby(\"predicted_product_category\")[\"count_new_id\"]\n",
        "       .transform(\"sum\")\n",
        ")\n",
        "\n",
        "out[\"count_do_recommend_by_category\"] = (\n",
        "    out.groupby(\"predicted_product_category\")[\"count_doRecommend\"]\n",
        "       .transform(\"sum\")\n",
        ")\n",
        "\n",
        "out['positive_sentiment_ratio'] = out['count_positive'] / out['count_new_id']\n",
        "out['negative_sentiment_ratio'] = out['count_negative'] / out['count_new_id']\n",
        "out['neutral_sentiment_ratio'] = out['count_neutral'] / out['count_new_id']\n",
        "\n",
        "out['sentiment_score'] = out['positive_sentiment_ratio'] - out['negative_sentiment_ratio']\n",
        "out['rating_score'] = out['sum_rating']/5\n",
        "\n",
        "out['frequency_score'] = out['count_new_id'] / out['count_new_id_by_category']\n",
        "\n",
        "out['recommendation_score'] = out['count_doRecommend'] / out['count_do_recommend_by_category']\n",
        "\n",
        "\n",
        "out['total_score_1'] =0.35 * out['sentiment_score'] + 0.35 * out['rating_score'] + 0.15 * out['frequency_score'] + 0.15 * out['recommendation_score']\n",
        "out['total_score_2'] =0.4 * out['sentiment_score'] + 0.4 * out['rating_score'] + 0 * out['frequency_score'] + 0.2 * out['recommendation_score']\n",
        "\n",
        "\n",
        "out[\"best_rank_in_category\"] = (\n",
        "    out.groupby(\"predicted_product_category\")[\"total_score_1\"]\n",
        "      .rank(method=\"dense\", ascending=False).astype(int)\n",
        ")\n",
        "\n",
        "out[\"worst_rank_in_category\"] = (\n",
        "    out.groupby(\"predicted_product_category\")[\"total_score_1\"]\n",
        "      .rank(method=\"dense\", ascending=True).astype(int)\n",
        ")\n",
        "\n",
        "front_cols = ['best_rank_in_category', 'worst_rank_in_category', 'total_score_1', 'total_score_2']\n",
        "cols = front_cols + [col for col in out.columns if col not in front_cols]\n",
        "out = out[cols].sort_values(by=['predicted_product_category','total_score_1'], ascending=False).reset_index(drop=True)\n",
        "out['category_id'] = out['predicted_product_category'] + '_' + out['id']\n",
        "\n",
        "best_products = out[out['best_rank_in_category']<=3].sort_values(by=['predicted_product_category','best_rank_in_category'], ascending=True).reset_index(drop=True)\n",
        "worst_products = out[out['worst_rank_in_category']<=3].sort_values(by=['predicted_product_category','worst_rank_in_category'], ascending=True)\n",
        "worst_products = worst_products[~worst_products['category_id'].isin(best_products['category_id'])].reset_index(drop=True)\n",
        "df_summary = df_resampled.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9de3cd64",
      "metadata": {
        "id": "9de3cd64"
      },
      "source": [
        "### Adding the Reviews to Best and Worst Products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36de033a",
      "metadata": {
        "id": "36de033a"
      },
      "outputs": [],
      "source": [
        "df_summary['category_id'] = df_summary['predicted_product_category'] + '_' + df_summary['id']\n",
        "\n",
        "df_summary_best = df_summary[df_summary['category_id'].isin(best_products.category_id.unique())]\n",
        "df_summary_worst = df_summary[df_summary['category_id'].isin(worst_products.category_id.unique())]\n",
        "\n",
        "\n",
        "def make_summary_strings(products_df,\n",
        "summary_df,\n",
        "positive_label=\"positive\",\n",
        "negative_label=\"negative\"):\n",
        "\n",
        "\n",
        "    summary_strings = []\n",
        "\n",
        "    for row in products_df.itertuples(index=False):\n",
        "        col1 = row.category_id\n",
        "\n",
        "        # Sentiment proportions\n",
        "        col2 = row.positive_sentiment_ratio / (\n",
        "            row.positive_sentiment_ratio + row.negative_sentiment_ratio\n",
        "        )\n",
        "        col3 = row.negative_sentiment_ratio / (\n",
        "            row.positive_sentiment_ratio + row.negative_sentiment_ratio\n",
        "        )\n",
        "\n",
        "        # Get positive subset\n",
        "        df_subset_pos = (\n",
        "            summary_df\n",
        "            .loc[(summary_df['category_id'] == col1) &\n",
        "                 (summary_df['sentiment'] == positive_label)]\n",
        "            .sort_values(by='reviews.numHelpful', ascending=False)\n",
        "            .head(int(20 * col2))\n",
        "        )\n",
        "\n",
        "        # Get negative subset\n",
        "        df_subset_neg = (\n",
        "            summary_df\n",
        "            .loc[(summary_df['category_id'] == col1) &\n",
        "                 (summary_df['sentiment'] == negative_label)]\n",
        "            .sort_values(by='reviews.numHelpful', ascending=False)\n",
        "            .head(int(20 * col3))\n",
        "        )\n",
        "\n",
        "        # selected indexes\n",
        "        selected_idx = list(df_subset_pos.index) + list(df_subset_neg.index)\n",
        "\n",
        "        # extract & join text\n",
        "        review_texts = summary_df.loc[selected_idx, \"name_title_text\"].tolist()\n",
        "        summary_string = \" \".join(review_texts)\n",
        "\n",
        "        summary_strings.append(summary_string)\n",
        "\n",
        "    # Add new column (name auto-handled)\n",
        "    products_df[\"summary_reviews_string\"] = summary_strings\n",
        "\n",
        "    cols = ['category_id', 'predicted_product_category', 'id', 'count_new_id', 'brand_value', 'longest_name', 'summary_reviews_string']\n",
        "    products_df = products_df[cols]\n",
        "\n",
        "\n",
        "    return products_df\n",
        "\n",
        "best_products = make_summary_strings(best_products, df_summary_best)\n",
        "worst_products = make_summary_strings(worst_products, df_summary_worst)\n",
        "\n",
        "# use column \"summary_reviews_string\" to generate a summary for the product"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "automated-customer-reviews (Poetry)",
      "language": "python",
      "name": "micro-gpt-py3.11"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}